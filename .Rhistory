install.packages("datasets")
library(datasets)
library(datasets)
data("iris")
summary(iris)
summary(iris$Sepal.Length)
sum(is.na(iris))
install.packages("skimr")
library(skimr)
skim(iris)
library(tidyverse)
iris %>%
group_by(Species) %>%
skim()
plot(iris, col = "red")
hist(iris$Sepal.Width)
plot(iris$Sepal.Length, iris$Sepal.Width)
plot(iris$Sepal.Width, iris$Sepal.Length)
plot(iris$Sepal.Width, iris$Sepal.Length, xlab = "Sepal width", ylab = "Sepal lenght" )
install.packages("carat")
library(carat)
featurePlot(x = iris[,1:4],
y = iris$Species,
plot = "box",
strip = strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = iris[,1:4],
y = iris$Species,
plot = "box")
https://www.machinelearningplus.com/machine-learning/caret-package/
install.packages(c('caret', 'skimr', 'RANN', 'randomForest', 'fastAdaboost', 'gbm', 'xgboost', 'caretEnsemble', 'C50', 'earth'))
install.packages(c("caret", "skimr", "RANN", "randomForest", "fastAdaboost", "gbm", "xgboost", "caretEnsemble", "C50", "earth"))
library(carat)
featurePlot(x = iris[,1:4],
y = iris$Species,
plot = "box",
strip = strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot()
?featurePlot
??featurePLot
??featurePlot
detach("package:carat", unload = TRUE)
library(caret)
featurePlot(x = iris[,1:4],
y = iris$Species,
plot = "box",
strip = strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = iris[,1:4],
y = iris$Species,
plot = "box",
strip = strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
library(skimr)
library(datasets)
library(tidyverse)
library(carat)
trainingIndex <- createDataPartition(iris$Species, p = 0.8, list = FALSE)
detach("package:carat", unload = TRUE)
library(caret)
trainingIndex <- createDataPartition(iris$Species, p = 0.8, list = FALSE)
trainingSet <- iris[trainingIndex,]
testingSet <- iris[-trainingIndex,]
plot(trainingSet$Sepal.Width, trainingSet$Sepal.Length, xlab = "Training Set Sepal width", ylab = "Training Set Sepal lenght" )
plot(testingSet$Sepal.Width, testingSet$Sepal.Length, xlab = "Testing Set Sepal width", ylab = "Testing Set Sepal lenght" )
featurePlot(x = trainingSet[,1:4],
y = trainingSet$Species,
plot = "box",
strip = strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = testingSet[,1:4],
y = testingSet$Species,
plot = "box",
strip = strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = trainingSet[,1:4],
y = trainingSet$Species,
plot = "box",
strip = strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = testingSet[,1:4],
y = testingSet$Species,
plot = "box",
strip = strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
model <- train(Species ~ ., data = trainingSet,
method = "svmPoly",
na.action = na.omit,
preProcess= c("scale", "center"),
trControl = trainControl(method="cv", number=10),
TuneGrid = data.frame(degree=1, scale=1, C=1))
model <- train(Species ~ ., data = trainingSet,
method = "svmPoly",
na.action = na.omit,
preProcess= c("scale", "center"),
trControl = trainControl(method="cv", number=10),
TuneGrid = data.frame(degree=1, scale=1, C=1))
# Build CV model
model.cv <- train(Species ~ ., data = trainingSet,
method = "svmPoly",
na.action = na.omit,
trControl = trainControl(method="cv",number=10),
tuneGrid = data.frame(degree=1,scale=1,C=1)
)
model.training <- predict(model, trainingSet)
model.testing <- predict(model,testingSet)
model.cv <- predict(model.cv, trainingSet)
i
# Model performance
model.training.confusion <- confusionMatrix(model.training,trainingSet$Species)
model.testing.confusion <- confusionMatrix(model.testing,testingSet$Species)
model.cv.confusion <- confusionMatrix(model.cv,trainingSet$Species)
model.training.confusion
model.testing.confusion
model.cv.confusion
set.seed(100)
trainingIndex <- createDataPartition(iris$Species, p = 0.8, list = FALSE)
trainingIndex <- createDataPartition(iris$Species, p = 0.8, list = FALSE)
trainingSet <- iris[trainingIndex,]
testingSet <- iris[-trainingIndex,]
plot(trainingSet$Sepal.Width, trainingSet$Sepal.Length, xlab = "Training Set Sepal width", ylab = "Training Set Sepal lenght" )
plot(testingSet$Sepal.Width, testingSet$Sepal.Length, xlab = "Testing Set Sepal width", ylab = "Testing Set Sepal lenght" )
featurePlot(x = trainingSet[,1:4],
y = trainingSet$Species,
plot = "box",
strip = strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = testingSet[,1:4],
y = testingSet$Species,
plot = "box",
strip = strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
model <- train(Species ~ ., data = trainingSet,
method = "svmPoly",
na.action = na.omit,
preProcess= c("scale", "center"),
trControl = trainControl(method="cv", number=10),
TuneGrid = data.frame(degree=1, scale=1, C=1)
)
# Build CV model
model.cv <- train(Species ~ ., data = trainingSet,
method = "svmPoly",
na.action = na.omit,
trControl = trainControl(method="cv",number=10),
tuneGrid = data.frame(degree=1,scale=1,C=1)
)
model.training <- predict(model, trainingSet)
model.cv <- predict(model.cv, trainingSet)
# Model performance
model.training.confusion <- confusionMatrix(model.training,trainingSet$Species)
model.testing.confusion <- confusionMatrix(model.testing,testingSet$Species)
model.cv.confusion <- confusionMatrix(model.cv,trainingSet$Species)
model.training.confusion
model.testing.confusion
model.cv.confusion
#Feature Importance
Importance <- varImp(model)
plot(Importance)
View(model)
